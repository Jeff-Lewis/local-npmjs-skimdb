{
 "metadata": {
  "name": "",
  "signature": "sha256:bd4aed8ab5e58b01f2eb2bc360de1c5e3309694bee14217ed17899a3729b3415"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "import datetime as dt\n",
      "import random\n",
      "import scipy as sc\n",
      "import scipy.stats as ss\n",
      "import statsmodels.api as smapi\n",
      "import statsmodels.graphics as smgraphics \n",
      "from statsmodels.formula.api import ols\n",
      "from scipy.optimize import curve_fit\n",
      "from scipy.interpolate import interp1d\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 291
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load data files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# metadata about packages\n",
      "d_meta = pd.read_csv('../data/packages_meta.csv')\n",
      "\n",
      "# dependency data\n",
      "d_deps = pd.read_csv('../data/packages_dependencies.csv')\n",
      "d_dev_deps = pd.read_csv('../data/packages_devDependencies.csv')\n",
      "d_all_deps = pd.read_csv('../data/packages_both.csv')\n",
      "\n",
      "# keyword network\n",
      "d_keywords = pd.read_csv('../data/keyword_packages.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 439
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats = {\n",
      "    \"quantiles\" : {}\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 441
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Normalize Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# normalize dates metadata\n",
      "d_meta['createdAt'] = pd.to_datetime(d_meta['created'],unit='s')\n",
      "d_meta['modifiedAt'] = pd.to_datetime(d_meta['modified'],unit='s')\n",
      "d_meta['deltaSinceModified'] = datetime.datetime.now() - d_meta['modifiedAt']\n",
      "d_meta['age'] = (datetime.datetime.now() - d_meta['createdAt']).apply(lambda x: np.timedelta64(x,'D') / np.timedelta64(1, 'D'))\n",
      "d_meta['delta'] = (d_meta.modifiedAt - d_meta.createdAt).apply(lambda x: np.timedelta64(x,'D') / np.timedelta64(1, 'D'))\n",
      "d_meta['log_delta'] = log(d_meta.delta)\n",
      "d_meta['deltaSinceModifiedDays'] = d_meta.deltaSinceModified.apply(lambda x: np.timedelta64(x, 'D').astype(int))\n",
      "\n",
      "# noramlize time data in dependencies\n",
      "d_deps['diff_between_deps'] = d_deps.deep_dependents - d_deps.direct_dependents \n",
      "d_dev_deps['diff_between_deps'] = d_dev_deps.deep_dependents - d_dev_deps.direct_dependents \n",
      "d_all_deps['diff_between_deps'] = d_all_deps.deep_dependents - d_all_deps.direct_dependents "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 442
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Remove outliers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove some outliers\n",
      "subset = d_meta[\n",
      "    (d_meta.version_major < 100) & \n",
      "    (d_meta.version_minor < 100) & \n",
      "    (pd.notnull(d_meta.created)) & \n",
      "    (pd.notnull(d_meta.modified)) &\n",
      "    (d_meta.age < 16000)]\n",
      "\n",
      "\n",
      "print( len(subset)/float(len(d_meta)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.995337465173\n"
       ]
      }
     ],
     "prompt_number": 443
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Compute percentiles function\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_nearest(my_list, value):\n",
      "    x = [max(x[1],value) for x in my_list]\n",
      "    \n",
      "    # to find the last index... this seems crazy.\n",
      "    x.reverse()\n",
      "\n",
      "    if value in x:\n",
      "        idx = len(x) - x.index(value) - 1\n",
      "        v =  my_list[idx]\n",
      "    else:\n",
      "        v = my_list[0]\n",
      "\n",
      "    return v\n",
      "\n",
      "def whichQuantile(df, new_prop, current_prop, write=False, quantiles=[0.1,0.2,0.3, 0.4,0.5,0.6, 0.7, 0.8, 0.9,1]):\n",
      "    current_max = df[current_prop].max()\n",
      "    percents = df[current_prop] / current_max\n",
      "    \n",
      "    qs = [(x,df[current_prop].quantile(q=x)) for x in quantiles]\n",
      "\n",
      "    stats[\"quantiles\"][current_prop] = qs\n",
      "    \n",
      "    if (write):\n",
      "        df[new_prop] = [find_nearest(qs, x)[0] for x in df[current_prop]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 444
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "whichQuantile(subset, 'age_quantiles', 'age', True)\n",
      "whichQuantile(subset, 'version_count_quantiles','version_count', True)\n",
      "whichQuantile(subset, 'deltaSinceModified_quantiles', 'deltaSinceModifiedDays', True)\n",
      "whichQuantile(subset, 'delta_quantiles','delta', True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 445
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the percentiles for some subset\n",
      "def compute_percentiles(df, d_meta, output, count=5000, sortfn=None):\n",
      "    \n",
      "    # Should we track this again?\n",
      "    # df['depends_on_count_percent_p'] = df.depends_on_count / df.depends_on_count.max()\n",
      "    df['direct_dependents_count_p'] = df.direct_dependents  / df.direct_dependents.max()\n",
      "    df['deep_dependent_count_p'] = df.deep_dependents / df.deep_dependents.max()\n",
      "    df['diff_between_deps_p'] = df.diff_between_deps / df.diff_between_deps.max()\n",
      "\n",
      "    # combine with metadata\n",
      "    merged_subset = pd.merge(df, d_meta, left_on=['package'], right_on=['id'], how='left')\n",
      "    merged_subset['package'] = merged_subset['id']\n",
      "    \n",
      "    merged_subset.drop('id', inplace=True, axis=1)\n",
      "    \n",
      "    merged_subset['delta_p'] = merged_subset.delta / merged_subset.delta.max()\n",
      "    merged_subset['version_count_p'] = merged_subset.version_count / merged_subset.version_count.max()\n",
      "    \n",
      "    # remove some outliers\n",
      "    merged_subset = merged_subset[merged_subset.version_major < 68]\n",
      "    \n",
      "    if (sortfn):\n",
      "        merged_subset = sortfn(merged_subset)\n",
      "    \n",
      "    s =  merged_subset[0:count]\n",
      "    s.to_json(orient='records', path_or_buf=output)\n",
      "    \n",
      "    return s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 446
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Subsets we want to get:\n",
      "\n",
      "* Longest running projects [50] - delta between now and created date\n",
      "* Most used packages [50] - based on deep dependencies\n",
      "* Most mature packages [50] - based on major version\n",
      "* Most releases [50] - packages with the most versions\n",
      "* Least known, most valuable packages [50] - those packages that have few direct dependents but have high deep dependencies."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Longest running projects\n",
      "def sortByAge(df):\n",
      "    return df.sort(['age'], ascending=[0])\n",
      "\n",
      "longest_running = compute_percentiles(d_deps, subset, 'longest_running_projects.json', sortfn=sortByAge)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 447
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Most used packages\n",
      "def sortByDeepDependents(df):\n",
      "    return df.sort(['deep_dependents'], ascending=[0])\n",
      "\n",
      "most_used = compute_percentiles(most_used_packages, subset, 'most_used_projects.json', sortfn=sortByDeepDependents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 448
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Most mature packages\n",
      "def sortByVersions(df):\n",
      "    return df.sort(['version_major','version_minor','version_patch'], ascending=[0,0,0])\n",
      "\n",
      "most_mature = compute_percentiles(d_deps, subset, 'most_mature_projects.json', sortfn=sortByVersions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 449
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Most releases\n",
      "def sortByVersionCount(df):\n",
      "    return df.sort(['version_count'], ascending=[0])\n",
      "\n",
      "most_versions = compute_percentiles(d_deps, subset, 'most_versions.json', sortfn=sortByVersionCount)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 450
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Least known, most valuable\n",
      "def sortByBiggestDiff(df):\n",
      "    return df.sort(['diff_between_deps'], ascending=[0])\n",
      "\n",
      "most_valuable = compute_percentiles(d_deps, subset, 'most_surprisingly_valuable.json', sortfn=sortByBiggestDiff)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 451
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Just merge the two for working copy\n",
      "all_packages = compute_percentiles(d_deps, subset, 'all_packages_merged_with_deps.json', count=len(subset))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 452
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Assemble general stats:\n",
      "\n",
      "1. How do versions break down across 0, 1 and >1?\n",
      "2. How long since packages have been updated?\n",
      "3. Get top keywords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zero = len(subset[subset.version_major == 0])\n",
      "one =  len(subset[subset.version_major == 1])\n",
      "gt_one = len(subset[subset.version_major > 1])\n",
      "total = float(len(subset))\n",
      "\n",
      "# Total packages we're looking at\n",
      "stats['total'] = total\n",
      "\n",
      "# Size of a quantile block\n",
      "stats['quantiles']['blocksize'] = total / 10\n",
      "\n",
      "# Version breakdown\n",
      "stats['version_breakdown'] = {\n",
      "    'zero' : zero,\n",
      "    'zero_p': zero / total,\n",
      "    'one' : one,\n",
      "    'one_p' : one / total,\n",
      "    'gt_one': gt_one,\n",
      "    'gt_one_p' : gt_one / total\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 453
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build since modified days\n",
      "x = stats['quantiles']['deltaSinceModifiedDays']\n",
      "\n",
      "# (quantile, total days, total years, total months, total days)\n",
      "x = [(d[0], int(d[1]), int(d[1] / 365)) for d in x]\n",
      "x = [(d[0], d[1], d[2], (d[1] - d[2] * 365) / 30) for d in x]\n",
      "x = [(d[0], d[1], d[2], d[3], (d[1] % 365) - (30 * d[3])) for d in x]\n",
      "\n",
      "stats['quantiles']['deltaSinceModifiedDays'] = x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 487
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add quantiles for package counts\n",
      "whichQuantile(all_packages, 'direct_dependents_quantiles','direct_dependents', True)\n",
      "whichQuantile(all_packages, 'deep_dependents_quantiles','deep_dependents', True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 488
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top 100 keywords used by the top highest deep dependent count packages\n",
      "from collections import Counter\n",
      "l = all_packages.sort(['deep_dependents'], ascending=[0])[0:1000].keywords.values\n",
      "l =  [x.split(',') for x in l if str(x) != 'nan']\n",
      "l = reduce(lambda x,y: x+y,l)\n",
      "c = Counter(l)\n",
      "stats['top_deep_dependents_keywords'] = dict((k, v) for k, v in c.items() if (v > 6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 489
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top 100 keywords used by the top highest direct dependent count packages\n",
      "from collections import Counter\n",
      "l = all_packages.sort(['direct_dependents'], ascending=[0])[0:1000].keywords.values\n",
      "l =  [x.split(',') for x in l if str(x) != 'nan']\n",
      "l = reduce(lambda x,y: x+y,l)\n",
      "c = Counter(l)\n",
      "stats['top_direct_dependents_keywords'] = dict((k, v) for k, v in c.items() if (v > 6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 490
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Top 100 keywords\n",
      "keywords = {}\n",
      "top_keywords =  d_keywords.sort(['package_count'], ascending=[0])[0:100]\n",
      "for count, row in top_keywords.iterrows():\n",
      "    keywords[row[0]] = row[1]\n",
      "stats['top_keywords'] = keywords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 525
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "with open('stats.json', 'wb') as fp:\n",
      "    json.dump(stats, fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 535
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}