{
 "metadata": {
  "name": "",
  "signature": "sha256:3cffc48a300d52e3549087bccdad5d5e6fb67863903622571d98e9424381f34a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "import datetime as dt\n",
      "import random\n",
      "import scipy as sc\n",
      "import scipy.stats as ss\n",
      "import statsmodels.api as smapi\n",
      "import statsmodels.graphics as smgraphics \n",
      "from statsmodels.formula.api import ols\n",
      "from scipy.optimize import curve_fit\n",
      "from scipy.interpolate import interp1d\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load data files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# metadata about packages\n",
      "d_meta = pd.read_csv('../data/packages_meta.csv')\n",
      "\n",
      "# dependency data\n",
      "d_deps = pd.read_csv('../data/packages_dependencies.csv')\n",
      "d_dev_deps = pd.read_csv('../data/packages_devDependencies.csv')\n",
      "d_all_deps = pd.read_csv('../data/packages_both.csv')\n",
      "\n",
      "# keyword network\n",
      "d_keywords = pd.read_csv('../data/keyword_packages.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats = {\n",
      "    \"quantiles\" : {}\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Normalize Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# normalize dates metadata\n",
      "d_meta['createdAt'] = pd.to_datetime(d_meta['created'],unit='s')\n",
      "d_meta['modifiedAt'] = pd.to_datetime(d_meta['modified'],unit='s')\n",
      "d_meta['deltaSinceModified'] = datetime.datetime.now() - d_meta['modifiedAt']\n",
      "d_meta['age'] = (datetime.datetime.now() - d_meta['createdAt']).apply(lambda x: np.timedelta64(x,'D') / np.timedelta64(1, 'D'))\n",
      "d_meta['delta'] = (d_meta.modifiedAt - d_meta.createdAt).apply(lambda x: np.timedelta64(x,'D') / np.timedelta64(1, 'D'))\n",
      "d_meta['log_delta'] = log(d_meta.delta)\n",
      "d_meta['deltaSinceModifiedDays'] = d_meta.deltaSinceModified.apply(lambda x: np.timedelta64(x, 'D').astype(int))\n",
      "\n",
      "# noramlize time data in dependencies\n",
      "d_deps['diff_between_deps'] = d_deps.deep_dependents - d_deps.direct_dependents \n",
      "d_dev_deps['diff_between_deps'] = d_dev_deps.deep_dependents - d_dev_deps.direct_dependents \n",
      "d_all_deps['diff_between_deps'] = d_all_deps.deep_dependents - d_all_deps.direct_dependents "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Remove outliers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove some outliers\n",
      "subset = d_meta[\n",
      "    (d_meta.version_major < 100) & \n",
      "    (d_meta.version_minor < 100) & \n",
      "    (pd.notnull(d_meta.created)) & \n",
      "    (pd.notnull(d_meta.modified)) &\n",
      "    (d_meta.age < 16000)]\n",
      "\n",
      "\n",
      "print( len(subset)/float(len(d_meta)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.995337465173\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Compute percentiles function\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_nearest(my_list, value):\n",
      "    x = [max(x[1],value) for x in my_list]\n",
      "    \n",
      "    # to find the last index... this seems crazy.\n",
      "    x.reverse()\n",
      "\n",
      "    if value in x:\n",
      "        idx = len(x) - x.index(value) - 1\n",
      "        v =  my_list[idx]\n",
      "    else:\n",
      "        v = my_list[0]\n",
      "\n",
      "    return v\n",
      "\n",
      "def whichQuantile(df, new_prop, current_prop, write=False, quantiles=[0.1,0.2,0.3, 0.4,0.5,0.6, 0.7, 0.8, 0.9,1]):\n",
      "    current_max = df[current_prop].max()\n",
      "    percents = df[current_prop] / current_max\n",
      "    \n",
      "    qs = [(x,df[current_prop].quantile(q=x)) for x in quantiles]\n",
      "\n",
      "    stats[\"quantiles\"][current_prop] = qs\n",
      "    \n",
      "    if (write):\n",
      "        df[new_prop] = [find_nearest(qs, x)[0] for x in df[current_prop]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "whichQuantile(subset, 'age_quantiles', 'age', True)\n",
      "whichQuantile(subset, 'version_count_quantiles','version_count', True)\n",
      "whichQuantile(subset, 'deltaSinceModified_quantiles', 'deltaSinceModified', True)\n",
      "whichQuantile(subset, 'delta_quantiles','delta', True)\n",
      "print stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'quantiles': {'maintainer_count': [(0.1, 1.0), (0.2, 1.0), (0.3, 1.0), (0.4, 1.0), (0.5, 1.0), (0.6, 1.0), (0.7, 1.0), (0.8, 1.0), (0.9, 1.0), (1, 29)], 'diff_between_deps': [(0.1, 0.0), (0.2, 0.0), (0.3, 0.0), (0.4, 0.0), (0.5, 0.0), (0.6, 0.0), (0.7, 0.0), (0.8, 0.0), (0.9, 1.0), (1, 65831)], 'age': [(0.1, 55.0), (0.2, 102.0), (0.3, 150.0), (0.4, 208.0), (0.5, 281.0), (0.6, 370.0), (0.7, 474.0), (0.8, 605.0), (0.9, 819.0), (1, 1359.0)], 'direct_dependents': [(0.1, 0.0), (0.2, 0.0), (0.3, 0.0), (0.4, 0.0), (0.5, 0.0), (0.6, 0.0), (0.7, 0.0), (0.8, 1.0), (0.9, 2.0), (1, 6542)], 'version_count': [(0.1, 1.0), (0.2, 1.0), (0.3, 1.0), (0.4, 2.0), (0.5, 3.0), (0.6, 3.0), (0.7, 5.0), (0.8, 7.0), (0.9, 11.0), (1, 410.0)], 'delta': [(0.1, 0.0), (0.2, 0.0), (0.3, 0.0), (0.4, 0.0), (0.5, 3.0), (0.6, 19.0), (0.7, 62.0), (0.8, 147.0), (0.9, 327.0), (1, 1311.0)], 'deep_dependents': [(0.1, 0.0), (0.2, 0.0), (0.3, 0.0), (0.4, 0.0), (0.5, 0.0), (0.6, 0.0), (0.7, 0.0), (0.8, 1.0), (0.9, 5.0), (1, 65952)], 'deltaSinceModified': [(0.1, numpy.timedelta64(2336220976468000,'ns')), (0.2, numpy.timedelta64(4733049707067999,'ns')), (0.3, numpy.timedelta64(7685253029068000,'ns')), (0.4, numpy.timedelta64(11026302863067998,'ns')), (0.5, numpy.timedelta64(15301325132268000,'ns')), (0.6, numpy.timedelta64(21326192371468000,'ns')), (0.7, numpy.timedelta64(29283592364667996,'ns')), (0.8, numpy.timedelta64(40106016475868000,'ns')), (0.9, numpy.timedelta64(56794504213668024,'ns')), (1, numpy.timedelta64(117475547378268000,'ns'))]}}\n"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the percentiles for some subset\n",
      "def compute_percentiles(df, d_meta, output, count=100, sortfn=None):\n",
      "    \n",
      "    # Should we track this again?\n",
      "    # df['depends_on_count_percent_p'] = df.depends_on_count / df.depends_on_count.max()\n",
      "    df['direct_dependents_count_p'] = df.direct_dependents  / df.direct_dependents.max()\n",
      "    df['deep_dependent_count_p'] = df.deep_dependents / df.deep_dependents.max()\n",
      "    df['diff_between_deps_p'] = df.diff_between_deps / df.diff_between_deps.max()\n",
      "\n",
      "    # combine with metadata\n",
      "    merged_subset = pd.merge(df, d_meta, left_on=['package'], right_on=['id'], how='inner')\n",
      "    merged_subset['package'] = merged_subset['id']\n",
      "    \n",
      "    merged_subset.drop('id', inplace=True, axis=1)\n",
      "    merged_subset.drop('direct_dependents', inplace=True, axis=1)\n",
      "    \n",
      "    merged_subset['delta_p'] = merged_subset.delta / merged_subset.delta.max()\n",
      "    merged_subset['version_count_p'] = merged_subset.version_count / merged_subset.version_count.max()\n",
      "    \n",
      "    # remove some outliers\n",
      "    merged_subset = merged_subset[merged_subset.version_major < 68]\n",
      "    \n",
      "    if (sortfn):\n",
      "        merged_subset = sortfn(merged_subset)\n",
      "        \n",
      "    merged_subset[0:count].to_json(orient='records', path_or_buf=output)\n",
      "    \n",
      "    return merged_subset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Subsets we want to get:\n",
      "\n",
      "* Longest running projects [50] - delta between now and created date\n",
      "* Most used packages [50] - based on deep dependencies\n",
      "* Most mature packages [50] - based on major version\n",
      "* Most releases [50] - packages with the most versions\n",
      "* Least known, most valuable packages [50] - those packages that have few direct dependents but have high deep dependencies."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Longest running projects\n",
      "def sortByAge(df):\n",
      "    return df.sort(['age'], ascending=[0])\n",
      "\n",
      "merged_dataset = compute_percentiles(d_deps, subset, 'longest_running_projects.json', sortfn=sortByAge)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Most used packages\n",
      "most_used_packages = d_deps.sort(['deep_dependents'], ascending=[0])\n",
      "merged_dataset = compute_percentiles(most_used_packages, subset, 'most_used_projects.json')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Most mature packages\n",
      "def sortByVersions(df):\n",
      "    return df.sort(['version_major','version_minor','version_patch'], ascending=[0,0,0])\n",
      "\n",
      "merged_dataset = compute_percentiles(d_deps, subset, 'most_mature_projects.json', sortfn=sortByVersions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Most releases\n",
      "def sortByVersionCount(df):\n",
      "    return df.sort(['version_count'], ascending=[0])\n",
      "\n",
      "merged_dataset = compute_percentiles(d_deps, subset, 'most_versions.json', sortfn=sortByVersionCount)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Least known, most valuable\n",
      "def sortByBiggestDiff(df):\n",
      "    return df.sort(['diff_between_deps'], ascending=[0])\n",
      "\n",
      "merged_dataset = compute_percentiles(d_deps, subset, 'most_surprisingly_valuable.json', sortfn=sortByBiggestDiff)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}